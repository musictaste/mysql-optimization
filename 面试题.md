[TOC]

# mysql基础架构


![101](738FC906D6004E02AF17FE10DBCF2ECF)

![102](9926C4CCCEE84228986DBB31858932EE)

## 1. **客户端**：向数据库发送请求

## 2. **Mysql Server** -》 连接器、分析器(抽象语法树AST)、优化器(执行计划、索引选择;RBO/CBO)、执行器(操作引擎，返回结果)、查询缓存(8.0以后被废除)

-  1.连接器：管理连接，权限认证(用户名密码验证)

    sql请求

- 2.分析器：词法分析，语法分析

    from where  
    语法分析 -》**抽象语法树AST**

- 3.优化器：执行计划，索引选择

    优化sql语句，规定执行流程
    
    RBO:基于规则的优化  
    ==CBO:基于成本的优化  -使用较多==
    
    可以查看sql语句的执行计划，可以采用对应的优化点，来加快查询

- 4.执行器：操作引擎，返回结果

    sql语句的实际执行组件  
    跟存储引擎挂钩

- 存储缓存，在mysql8.0以后被废除了

    **提升缓存命中率：将不变的数据放到缓存中**

    ==大部分操作发生在：分析器、优化器==

## 3. 存储引擎 InnoDB、MyISAM、memory;performance_schema

    不同的文件位置、不同的文件格式  
    InnoDB：磁盘  
    MyISAM：磁盘  
    Memory：内存  

### 存储引擎InnoDB(.frm/.ibd)、MyISAM(.MYD/.MYI)的数据文件格式 ：    
    .frm 表结构
    .ibd 存储的数据文件，代表存储引擎为InnoDB
    .MYD【数据文件】或.MYI【索引文件】代表存储引擎为MyASM
    
# 性能监控

## 使用show profile查询剖析工具，可以指定具体的type -》 set profling=1;show profiles;show profile for query ID;

此工具默认是禁用的，可以通过服务器变量在绘画级别动态的修改

#低版本可以用，官网有明确的提示:未来可能会被弃用

当设置完成之后，在服务器上执行的所有语句，都会测量其耗费的时间和其他一些查询执行状态变更相关的数据。

    set profling=1
    
    --在mysql的命令行模式下只能显示两位小数的时间，可以使用如下命令查看具体的执行时间
    show profiles; 
    
    --默认为最近一条查询
    show profile;
       
    --执行如下命令可以查看详细的每个步骤的时间： 
    --查看queryID=1的执行时间，默认为最近一条查询
    show profile for query 1;  
    #starting  开始运行，准备mysql服务  浪费时间
    #sengding data 发送数据  浪费实际
    #这两个浪费时间，是正常的
    
    #type
    # \G更容易查看，由列表改为信息展示
	--all：显示所有性能信息
	show profile all for query n\G;
	--block io：显示块io操作的次数
	show  profile block io for query n
	--context switches：显示上下文切换次数，被动和主动
	show profile context switches for query n
	--cpu：显示用户cpu时间、系统cpu时间
	show profile cpu for query n
	--IPC：显示发送和接受的消息数量
	show profile ipc for query n
	--Memory：暂未实现
	--page faults：显示页错误数量
	show profile page faults for query n
	--source：显示源码中的函数名称与位置
	show profile source for query n
	--swaps：显示swap的次数
	show profile swaps for query n
	
## 2.使用performance schema来更加容易的监控mysql

注意一个悖论：因为Schema是监控程序，长时间运行，会占用系统资源，但是不能因为占用系统资源，所以不开启Schema

另外，Mysql 5.7默认开启了Schema；

可以开发一套schema监控系统，有兴趣自己做，没兴趣算了

利用schema可以做mysql监控

schema监控一般如果是公司使用，都是内部使用，不会开源

运维监控也不用schema，更多关注的是整个服务器的性能

### 问题：调优时，mysql语句、执行计划都没有问题，但是mysql就是慢，怎么解决？-> -》就是这部分知识，mysql服务中执行了哪些线程？这些线程分别做什么事情？这些事情分别用了多长时间？占用了多少资源？

## 3.使用show processlist查看连接的线程个数，来观察是否有大量线程处于不正常的状态或者其他不正常的特征【这个在优化时，优化比较少】

```
id表示session id
user表示操作的用户
host表示操作的主机
db表示操作的数据库
command表示当前状态
	sleep：线程正在等待客户端发送新的请求**
	query：线程正在执行查询或正在将结果发送给客户端
	locked：在mysql的服务层，该线程正在等待表锁**
	analyzing and statistics：线程正在收集存储引擎的统计信息，并生成查询的执行计划
	Copying to tmp table：线程正在执行查询，并且将其结果集都复制到一个临时表中
	sorting result：线程正在对结果集进行排序
	sending data：线程可能在多个状态之间传送数据，或者在生成结果集或者向客户端返回数据
info表示详细的sql语句
time表示相应命令执行时间
state表示命令执行状态
```

# MYSQL performance schema详解

**MySQL的performance schema 用于监控MySQL server在一个较低级别的运行过程中的资源消耗、资源等待等情况**。

==在mysql的5.7版本中，性能模式是默认开启的==，如果想要显式的关闭的话需要修改配置文件，不能直接进行修改，会报错Variable 'performance_schema' is a read only variable。

## 特点如下：-> performance_schema存储引擎/数据库，事件，server源代码中的检测点、只记录在本地，不会写入binlog，复制时也不会复制；保存在内存中，服务器重启就没有了

实时检查server的内部执行情况

performance_schema存储引擎

performance_schema 数据库

事件(只记录在本地server的数据库表中)

通过监控server的事件来实现监控server的内部运行情况

server源代码中的“检测点”来实现事件数据的收集、

performance_schema中的事件只记录在本地server的performance_schema中，其下的这些表中数据发生变化时不会被写入binlog中，也不会通过复制机制被复制到其他server中。

==performance_schema中的事件只记录在本地server的performance_schema中，其下的这些表中数据发生变化时不会被写入binlog中，也不会通过复制机制被复制到其他server中==。


可以使用SQL语句更新performance_schema数据库中的表记录，（如动态修改performance_schema的setup_*开头的几个配置表，但要注意：**配置表的更改会立即生效**，这会影响数据收集）

==performance_schema的表中的数据不会持久化存储在磁盘中，而是保存在内存中，一旦服务器重启，这些数据会丢失==（包括配置表在内的整个performance_schema下的所有数据）

### performance_schema VS information_schema -> 运行过程中的性能相关数据 VS 元数据信息

performance_schema数据库主要关注 数据库运行过程中的性能相关的数据，

information_schema主要关 注server运行过程中的元数据信息

## performance schema入门 -》 mysql5.7默认开启；show variables like 'performance_schema'; 配置文件mysqld(performance_schema=on); instruments生产者、consumers消费者

​		==在mysql的5.7版本中，性能模式是默认开启的==，如果想要显式的关闭的话需要修改配置文件，不能直接进行修改，会报错Variable 'performance_schema' is a read only variable。

​		**instruments**:生产者，用于采集mysql中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项。

​		**consumers**:消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项。

**数据库刚刚初始化并启动时**，**并非所有instruments和consumers都启用了**，所以默认不会收集所有的事件，可能你需要检测的事件并没有打开，需要进行设置，可以使用如下两个语句打开对应的instruments和consumers（行计数可能会因MySQL版本而异)。

```sql
--查看performance_schema的属性
mysql> SHOW VARIABLES LIKE 'performance_schema';
+--------------------+-------+
| Variable_name      | Value |
+--------------------+-------+
| performance_schema | ON    |
+--------------------+-------+
1 row in set (0.01 sec)

--在配置文件中修改performance_schema的属性值，on表示开启，off表示关闭
[mysqld]
performance_schema=ON

--切换数据库
use performance_schema;

--查看当前数据库下的所有表,会看到有很多表存储着相关的信息
show tables;

--可以通过show create table tablename来查看创建表的时候的表结构
mysql> show create table setup_consumers\G;

select * from setup_instruments; # ENABLED:监控是否开启；TIMED:计时器是否开启



--打开等待事件的采集器配置项开关，需要修改setup_instruments配置表中对应的采集器配置项
UPDATE setup_instruments SET ENABLED = 'YES', TIMED = 'YES'where name like 'wait%';
```

# 面试题：市场上主流的数据库线程池有哪些？有什么区别【加分项】-》Druid、DBCP、C3P0、BoneCP、Proxool、Jboss、tomcat-jdbc；比较点：LRU、PScache、PScache-oracle-optimized、ExceptionSorter

## C3P0（老项目）,有PSCache

## Proxool:如果你使用Oracle、SQL Server、DB2、Sybase这样支持游标的数据库就不用考虑了


现在市面上的数据库连接池：DBCP(很少使用)   C3P0（老项目）  druid（德鲁伊 性能很强）【性能监控信息-github中文文档，面试时可以帮到】

==日本的BoneCP，连接比druid快，但是一些复杂的功能不支撑，例如：PScache、ExceptionSorter==

https://github.com/alibaba/druid/wiki/%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%AF%B9%E6%AF%94

![103](299CB128AF1B432E9F506BB82BAFD87E)

**LRU** 

LRU是一个**性能关键指标**，特别Oracle，每个Connection对应数据库端的一个进程，如果数据库连接池遵从LRU，有助于数据库服务器优化，这是重要的指标。**在测试中，Druid、DBCP、Proxool是遵守LRU的。BoneCP、C3P0则不是。BoneCP在mock环境下性能可能好，但在真实环境中则就不好了。**

**PSCache**

PSCache是数据库连接池的关键指标。在Oracle中，类似SELECT NAME FROM USER WHERE ID = ?这样的SQL，**启用PSCache和不启用PSCache的性能可能是相差一个数量级的**。Proxool是不支持PSCache的数据库连接池，**如果你使用Oracle、SQL Server、DB2、Sybase这样支持游标的数据库，那你就==完全不用考虑Proxool==**。

**PSCache-Oracle-Optimized**

**Oracle 10系列的Driver**，如果开启PSCache，**会占用大量的内存**，必须做特别的处理，**启用内部的EnterImplicitCache等方法优化才能够减少内存的占用**。==这个功能只有DruidDataSource有==。如果你使用的是Oracle Jdbc，你应该毫不犹豫采用DruidDataSource。

**ExceptionSorter**

ExceptionSorter是一个很重要的**容错特性**，**如果一个连接产生了一个不可恢复的错误，必须立刻从连接池中去掉，否则会连续产生大量错误**。这个特性，**目前只有JBossDataSource和Druid实现**。Druid的实现参考自JBossDataSource，经过长期生产反馈补充。

## 在测试中，Druid、DBCP、Proxool是遵守LRU的。BoneCP、C3P0则不是。BoneCP在mock环境下性能可能好，但在真实环境中则就不好了 -》 LRU

## 如果你使用Oracle、SQL Server、DB2、Sybase这样支持游标的数据库，那你就完全不用考虑Proxool,因为不支持PScache

## Oracle 10系列的Driver如果开启PSCache，会占用大量的内存，必须做特别的处理，启用内部的EnterImplicitCache等方法优化才能够减少内存的占用。这个功能只有DruidDataSource-》 PSCache-Oracle-Optimized

# 书籍《高效能mysql》
# ===============================
# Schema与数据类型优化（面试不会问到，DBA会问到）

## ==数据类型的优化、合适使用范式和反范式、主键的选择、字符集的选择、存储引擎的选择、适当的数据冗余、适当拆分==

## 数据类型的优化

### 更小的数据类型通常更好

**不同的数据类型，文件大小是一样的，但是空间占用是不一样的**

### 简单更好 -》 更少的CPU周期(整型VS字符串，data VS String,整型存储IP地址【INET_ATON('192.168.85.111')、INET_NTOA('3232257391')】)

==简单数据类型的操作通常需要更少的CPU周期==，例如，

1、**整型比字符操作代价更低**，因为==字符集和校对规则==是字符比较比整型比较更复杂，

2、 **使用mysql自建类型而不是字符串来存储日期和时间**

3、**用整型存储IP地址**

### 尽量避免null -> null使的索引、索引统计和值比较 更加复杂

如果查询中包含可为NULL的列，对mysql来说很难优化，因为可为null的列使得索引、索引统计和值比较都更加复杂，**坦白来说，通常情况下null的列改为not null带来的性能提升比较小**，所有没有必要将所有的表的schema进行修改，**但是应该尽量避免设计成可为null的列**

### ==实际细则 ：整数类型、字符和字符串类型、BLOB和text、datetime和timestamp和date、使用枚举代替字符串类型==

#### 整数类型

可以使用的几种整数类型**TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT分别使用8，16，24，32，64位存储空间**

##### 面试题：mysql中字段定义为int(1)，可以存储100000吗？ -> 没有影响；跟底层存储字节数有关，int的默认为32位 定义的长度只是规范，

```sql
mysql> create table test_int(id int(1));
Query OK, 0 rows affected (0.01 sec)

mysql> insert into test_int values(100000);
Query OK, 1 row affected (0.00 sec)
```

##### 面试题：int长度改短会有什么影响？ -> 没有影响

#### 字符和字符串类型 -》 按照查询速度：char(255,定长)>varchar(可变，65535)>text(没有长度限制)

##### varchar VS char

##### varchar -> 255（额外一个字节保存长度；两个字节）;varchar(5)vs varchar(255) 硬盘存储空间，内存空间占用;**mysql5.6之前，变更长度或从255以下变为255以上会锁表**

1. 使用最小的符合需求的长度。
2. ==varchar(n) n小于等于255使用额外一个字节保存长度，n>255使用额外两个字节保存长度==。
3. **varchar(5)与varchar(255)保存同样的内容，硬盘存储空间相同，但内存空间占用不同，是指定的大小**
4. ==varchar在mysql5.6之前变更长度，或者从255一下变更到255以上时时，都会导致锁表==。

**应用场景**

1. 存储长度波动较大的数据，如：文章，有的会很短有的会很长
2. 字符串很少更新的场景，每次更新后都会重算并使用额外存储空间保存长度
3. 适合保存多字节字符，如：汉字，特殊字符等

##### char固定长度的字符串 -> 255;自动删除末尾的空格 ，检索、写效率高于varchar

1. 最大长度：255
2. ==会自动删除末尾的空格 【这是规定，不是bug】==
3. ==检索效率、写效率 会比varchar高，以空间换时间==

**应用场景**

1. 存储长度波动不大的数据，如：md5摘要
2. **存储短字符串、经常更新的字符串**

##### 问题：文件实际大小与占用空间有什么区别？

磁盘有page,4Kb, 使用4Kb是为了提高数据读取效率， 4K对齐；

一个文件大小为4.23Kb,会占用两个Page,所以占用空间为8Kb

##### InnoDB的存储引擎，每次读取16Kb的数据，提高磁盘和内存的IO效率

##### pagecache 4K对索引也有作用：3层B+树，意味着读3个磁盘块，12Kb的数据可以支撑百万级别的数据量，可以快速检索数据


#### BLOB和TEXT类型 -》 二进制、字符方式存储

**Text和Blob，一般不用，如果过长可以存放在文件中，将文件路径保存在数据表中**

MySQL 把每个 BLOB 和 TEXT 值当作一个独立的对象处理。

两者都是为了存储很大数据而设计的字符串类型，**分别采用二进制和字符方式存储**。

##### 面试题：varchar 长度改小会有什么影响？ -》 已有数据会报错，修改失败；插入，无法插入

```sql
# 如果已有数据的长度大于要修改的位宽，会报错，不能修改成功
# 另外如果插入的数据的长度大于规定的位宽，也无法插入

mysql> create database test;
mysql> use test;
mysql> create table test_varchar(name varchar(5));
mysql> insert into test_varchar values('12345');

mysql> insert into test_varchar values('12345678');
ERROR 1406 (22001): Data too long for column 'name' at row 1

mysql> alter table test_varchar modify name varchar(1);
ERROR 1265 (01000): Data truncated for column 'name' at row 1

```

#### datetime和timestamp

##### datetime-》 8个字节、时区无关、保存到毫秒

**占用8个字节**

==与时区无关，数据库底层时区配置，对datetime无效==

**可保存到毫秒**

可保存时间范围大

不要使用字符串存储日期类型，占用空间大，损失日期类型函数的便捷性

##### 	timestamp -》4个字节，整型存储、依赖数据库设置的时区(设置会自动更新timestamp值)、范围(1970-01-01到2038-01-19)

**占用4个字节**

==时间范围：1970-01-01到2038-01-19==

**精确到秒**

**采用整形存储**

==依赖数据库设置的时区==

自动更新timestamp列的值

###### 问题：知道timestamp的时间范围吗？为什么是这个范围？

    时间范围：1970-01-01到2038-01-19
    
    原因：4个字节，32位，能表示的值为4294967296，42亿多，从格林尼治时间1970-01-01开始，加上42亿毫秒，就是32038-01-19


##### 	date -》 3个字节，范围(1000-01-01到9999-12-31)，可以利用日期时间函数进行计算

占用的字节数比使用字符串、datetime、int存储要少，使用date类型**只需要3个字节**

使用date类型还可以利用**日期时间函数**进行日期之间的计算

date类型用于保存==1000-01-01到9999-12-31==之间的日期

#### 使用枚举代替字符串类型 -》 根据列表值压缩到一个或两个字节；值在列表中的位置保存为整数；.frm中保存“数字-字符串”映射关系的查找表 -》 排序跟插入的顺序无关，跟表字段的定义顺序有关

==枚举== -》数据字典

有时可以使用枚举类代替常用的字符串类型，mysql存储枚举类型会非常紧凑，会根据列表值的数据压缩到一个或两个字节中，mysql在内部会将每个值在列表中的位置保存为整数，并且在表的.frm文件中保存“数字-字符串”映射关系的查找表

```sql

create table enum_test(e enum('fish','apple','dog') not null);
insert into enum_test(e) values('fish'),('dog'),('apple');
select e+0 from enum_test;
select * from enum_test;

select * from enum_test order by e; # 排序跟插入的顺序无关，跟表字段的定义顺序有关
# 结果为：fish apple dog

select * from enum_test where e=1; //下标从0开始
select * from enum_test where e='fish';

alter table enum_test modify column (e enum('fish','apple','dog','cat'));

```


#### 特殊类型数据 -》 使用整型存储IP地址（可读性不好，但是存储空间更小）；INET_ATON，INET_NTOA

**人们经常使用varchar(15)来存储ip地址**，然而，它的本质是32位无符号整数不是字符串，可以使用**INET_ATON()和INET_NTOA**函数在这两种表示方法之间转换


```sql
-- 1.IP地址转整型  【整型：可读性不好，但是存储空间更小】
select INET_ATON('192.168.85.111')
select INET_NTOA('3232257391')
select INET_ATON('255.255.255.257')  #无法转换

```

#### ==存储过程现在不建议使用==

## 合理使用范式和反范式

### ==三范式(减少数据冗余)、范式(需要进行关联)、反范式、一般需要混合使用（有利于高效地获取数据，排序的需要）==

### 三范式：列不可分，不能存在传递依赖，必须唯一的依赖于主键 -》 减少数据冗余

1NF的定义为：列不可分；【符合1NF的关系中的每个属性都不可再分】  
2NF：不能存在传递依赖；【保证一张表只描述一件事情】  
3NF：必须唯一的依赖于主键；【保证每列都和主键直接相关】  
**三范式的作用：减少数据冗余**  
——基础课有讲范式

#### ==阿里规范：超过三站表，禁止使用join，为什么== -》原因：join过程慢；也得看数据量的大小，数据量少也很快

### 范式 -》 更新快，很少或者没有重复的数据 ，数据比较小，可以放在内存中，操作比较快 -》 需要进行关联

    优点  
    	范式化的更新通常比反范式要快  
    	当数据较好的范式化后，很少或者没有重复的数据  
    	范式化的数据比较小，可以放在内存中，操作比较快  
    
    缺点  
    	通常需要进行关联

	
### 反范式 -》 可以避免关联；可以设计有效的索引；-》表格内的冗余较多，删除数据时候会造成表有些有用的信息丢失

    优点  
    	所有的数据都在同一张表中，可以避免关联  
    	可以设计有效的索引；
    	
    缺点   
    	表格内的冗余较多，删除数据时候会造成表有些有用的信息丢失

### 注意 -》一般需要混合使用（有利于高效地获取数据，排序的需要）

在企业中很好能做到严格意义上的范式或者反范式，一般需要混合使用

在一个网站实例中，这个网站，允许用户发送消息，并且一些用户是付费用户。现在想查看付费用户最近的10条信息。

在user表和message表中都存储用户类型(account_type)而不用完全的反范式化。这避免了完全反范式化的插入和删除问题，因为即使没有消息的时候也绝不会丢失用户的信息。这样也不会把user_message表搞得太大，**有利于高效地获取数据**。

另一个：**从父表冗余一些数据到子表的理由是排序的需要**。

缓存**衍生值**也是有用的。如果需要显示每个用户发了多少消息（类似论坛的），可以每次执行一个昂贵的自查询来计算并显示它；也可以在user表中建一个num_messages列，每当用户发新消息时更新这个值。

全排序，意味着需要将数据全部加载到内存中，这个过程非常慢；解决：1.把数据放到一张表中；2.或使用索引，索引底层数据结构是B+树，本身就是有序树，可以按照当前列进行排序，不需要放到内存进行排序

#### **使用了limit不需要使用order by或order by 不生效-》 原因就是使用了索引的查询**

## ==主键的选择 -》自然主键、代理主键(推荐) -》 是否跟业务相关==

代理主键：例如id；与业务无关的，无意义的数字序列

自然主键：人的身份证号；事物属性中的自然唯一标识

==区分自然、代理主键：是否跟业务相关==

==推荐使用代理主键：==

1. 它们不与业务耦合，因此更容易维护
2. 一个大多数表，最好是全部表，通用的键策略能够减少需要编写的源码数量，减少系统的总体拥有成本

主键生成器：n种生成策略，

## **字符集的选择 -》合适的字符集可以减少数据量，进而减少IO操作次数；中文用utf8mb4;latin1(纯拉丁字符),uft8/unicode（多语言）,数据类型精确到具体字段**

==中文存储，不建议utf-8；中文有可能是2个或3个字符来存储；建议utf8mb4==

## 存储引擎的选择

engine默认为InnoDB，如何修改？my.inf -> default-storage-engine=INNODB（windows）

memory不能持久化

### ==MyISAM 和InnoDB的对比 -》 索引类型(非聚簇)、事务、表锁、行锁、外键、全文索引(InnoDB5.6后支持)、操作类型==

![203](192EA054C677408E905916308E36C637)

### 非聚簇索引（索引文件和数据文件不放在一起  ） VS 聚簇索引 （索引文件和数据文件放在一起）


### **区分InnoDB是表锁还是行锁？ 增删改查的列是否为索引列**

InnoDB存储引擎默认是给索引加锁；所以只需要判断一件事：增删改查的那个列是否是建索引的那个列；如果是索引列，就是行锁；否则为表锁

### 全文索引怎么理解？ -》 检索关键字  -》 搜索引擎

文章content字段，要检索是否有java关键字；一般企业中不会使用全文索引，因为效率低  -》其他方式：lson、solr、ES

### **为什么尽量不要使用like？-》like中有%，那么索引不生效**

### 存储引擎可以转换吗？-》**可以，但是需要注意：转换时需要对索引、列也进行转换，这个转换有很多需要注意的点，一般没人这么干**

## 适当的数据冗余 -》需要更新冗余数据 -》 空间换时间

### **物化视图 -》 sql执行结果放到物理表中（oracle） -》 uncommit(数据更新，更改物化视图)/undemand** 

**需要更新冗余数据，类似物化视图**

使用视图，需要提前执行sql语句；

==物化视图：oracle有，mysql没有==  

物化视图，把sql执行的结果提前放到一张物理表中；如果基表数据发生变化，那么物化视图也要进行更改；oracle提供两种机制：undemand、uncommit  

uncommit:基表的数据只要提交更新，那物化视图就进行更改  

undemand:对物化视图进行查询的时候，才会对物化视图进行更改

## 适当拆分-》 既减少物理 IO 次数，也能大大提高内存中的缓存命中率

当我们的表中存在类似于TEXT或者是很大的VARCHAR类型的大字段的时候，如果我们大部分访问这张表的时候都不需要这个字段，我们就该义无反顾的将其拆分到另外的独立表中，以减少常用数据所占用的存储空间。这样做的一个明显好处就是每个数据块中可以存储的数据条数可以大大增加，**既减少物理 IO 次数，也能大大提高内存中的缓存命中率**。

数据库字段的拆分是很重要的

### 提到拆分，大家会想到分库分表；分库分表是分两种层次，一种是水平切分【1到1000】、一种是垂直切分【业务切分】 -> 数据库字段的拆分是很重要的

业务切分、数据切分是很复杂的

数据库字段的拆分是很重要的

# =================================
# 执行计划

在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。

可以**使用explain+SQL语句来 模拟优化器执行SQL查询语句**，从而知道mysql是如何处理sql语句的。

官网地址： https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 

## 执行计划中包含的信息


### id -》 **id相同，从上往下；id不同，id值越大越线执行**

select查询的序列号，包含一组数字，表示查询中执行select子句或者操作表的顺序

id号分为三种情况：

1、==如果id相同，那么执行顺序从上到下==

2、如果id不同，如果是子查询，id的序号会递增，==id值越大优先级越高，越先被执行==

==也就是子查询优先执行==

id相同和不同的，同时存在：相同的可以认为是一组，从上往下顺序执行，在所有组中，id值越大，优先级越高，越先执行



### select_type -》 simple/primary/union/dependent union/union result/subquery/dependent subquery/derived/uncacheable union -> derived(from子句中出现的子查询，也叫派生类)

主要用来分辨查询的类型，是普通查询还是联合查询还是子查询

```sql
--sample:简单的查询，不包含子查询和union
explain select * from emp;

--primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primary
explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;

--union:若第二个select出现在union之后，则被标记为union
explain select * from emp where deptno = 10 union select * from emp where sal >2000;

--dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响
explain select * from emp e where e.empno  in ( select empno from emp where deptno = 10 union select empno from emp where sal >2000)

--union result:从union表获取结果的select
explain select * from emp where deptno = 10 union select * from emp where sal >2000;

--subquery:在select或者where列表中包含子查询
explain select * from emp where sal > (select avg(sal) from emp) ;

--dependent subquery:subquery的子查询要受到外部表查询的影响
explain select * from emp e where e.deptno in (select distinct deptno from dept);

--DERIVED: from子句中出现的子查询，也叫做派生类，
explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ;

--UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存
 explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size);
 
--uncacheable union:表示union的查询结果不能被缓存：sql语句未验证
```

### table -》 **derivedN / union n1,n2**

对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集

​		1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名

​		2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表

​		3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id

### type -> **system、const(至多有一个匹配行)、ref(非唯一索引)、range、index(覆盖索引、索引排序)、ALL** 

type显示的是访问类型，访问类型表示我是以何种方式去访问我们的数据，效率从最好到最坏依次是：

**system** > **const** > eq_ref > **ref** > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > **range** > **index** > **ALL** 

==一般情况下，得保证查询至少达到range级别，最好能达到ref==

index：主要有两种情况，一种是当前的查询时覆盖索引，即**我们需要的数据在索引中就可以索取**，或者是**使用了索引进行排序**，这样就避免数据的重排序

const：这个表至多有一个匹配行，

```sql
--all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。
explain select * from emp;

--index：全索引扫描 这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序
explain  select empno from emp;

--range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, <>, >, >=, <, <=, IS NULL, BETWEEN, LIKE, or IN() 
explain select * from emp where empno between 7000 and 7500;

--index_subquery：利用索引来关联子查询，不再扫描全表
explain select * from emp where emp.job in (select job from t_job);

--unique_subquery:该连接类型类似与index_subquery,使用的是唯一索引
 explain select * from emp e where e.deptno in (select distinct deptno from dept);
 
--index_merge：在查询过程中需要多个索引组合使用，没有模拟出来

--ref_or_null：对于某个字段既需要关联条件，也需要null值的情况下，查询优化器会选择这种访问方式
explain select * from emp e where  e.mgr is null or e.mgr=7369;

--ref：使用了非唯一性索引进行数据的查找
 create index idx_3 on emp(deptno);
 explain select * from emp e,dept d where e.deptno =d.deptno;

--eq_ref ：使用唯一性索引进行数据查找
explain select * from emp,emp2 where emp.empno = emp2.empno;

--const：这个表至多有一个匹配行，
explain select * from emp where empno = 7369;
 
--system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现
```

### possible_keys

​        **显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用**


### key -》 实际用到的索引

​		实际使用的索引，如果为null，则没有使用索引，查询中若使用了覆盖索引，则该索引和查询的select字段重叠。


### key_len

表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下**长度越短越好**。


### ref

显示索引的哪一列被使用了，如果可能的话，是一个常数



### rows

根据表的统计信息及索引使用情况，大致估算出找出所需记录需要读取的行数，此参数很重要，直接反应的sql找了多少数据，在完成目的的情况下**越少越好**


### extra -》 ==using filesort(无法利用索引进行排序)、temporary(临时表来保存中间结果)、index(代表是覆盖索引) 、using where(where进行条件过滤)-》using index + using where 表名(利用索引去表中读取数据,回表)==

==extra = using index 代表是索引覆盖==

包含额外的信息。

**using index**:这个表示当前的查询是覆盖索引的，直接从索引中读取数据，而不用访问数据表。**如果同时出现using where 表名**，索引被用来执行索引键值的查找，如果没有，**索引被用来读取数据**，而不是真的查找

```sql
--using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置
explain select * from emp order by sal;

--using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除
explain select ename,count(*) from emp where deptno = 10 group by ename;

--using index:这个表示当前的查询是覆盖索引的，直接从索引中读取数据，而不用访问数据表。
--如果同时出现using where 表名，索引被用来执行索引键值的查找，如果没有，索引被用来读取数据，而不是真的查找
explain select deptno,count(*) from emp group by deptno limit 10;

--using where:使用where进行条件过滤
explain select * from t_user where id = 1;

--using join buffer:使用连接缓存，情况没有模拟出来

--impossible where：where语句的结果总是false
explain select * from emp where empno = 7469;
```

# =======================================

## ==慢查询：是mysql非常重要的的核心点，有慢查询日志；开启慢查询，会有慢查询日志，可以根据慢查询日志进行优化==

## **mysql优化，首先要知道哪块执行慢，然后去优化；不能只根据执行计划就去优化**

# 通过索引进行优化

## ==索引采用的数据结构 -》哈希表(memory)和B+树（InnoDB、MYISAM）==

索引要记录偏移量

### hash表 -》 数组+链表 -》 **需要将数据全部读取到内存中；只能等值匹配**

数组+链表，进行散列算法（取模运算）

缺点：

1、利用hash存储的话需要将所有的数据文件添加到内存，比较耗费内存空间

2、如果所有的查询都是等值查询，那么hash确实很快，但是在企业或者实际工作环境中范围查找的数据更多，而不是等值查询，因此hash就不太适合了

### ==二叉树发展历程：二叉树-》BST 二叉搜索树 -》AVL平衡树 -》 红黑树(提高插入效率，损失查询效率) -》 B树 -》 B+树 -》B*树==

#### 二叉树：数据倾斜，造成IO成本

无论是二叉树还是红黑树，都会因为树的深度过深而造成io次数变多，影响数据读取的效率

#### BST二叉搜索树：树的每个节点都包含了健值 key、数据值 data、左子节点指针、右子节点指针

左旋右旋：保证当前最短子树和最长子树，长度差不能超过1

#### AVL平衡树:左旋右旋

平衡的二叉搜索树的查询效率更高。

每个节点的左右子节点的高度之差的绝对值最多为1，即平衡因子为范围为[-1,1]

缺点：插入效率极低、查询效率高；2.并且树也很深

---
    
#### AVL演化出红黑树 -》 O(logn) -> 旋转操作+变色功能 -》单分支中不能出现两个连续节点都为红色；每个分支中到达根节点的黑色节点个数必须一致 -》 提高插入效率，损失查询效率

自平衡二叉查找树

它与AVL树类似，都在插入和删除操作时能通过旋转操作保持二叉查找树的平衡

红黑(Red-black)树是一种**自平衡二叉查找树**，1972年由Rudolf Bayer发明，**它与AVL树类似，都在插入和删除操作时能通过旋转操作保持二叉查找树的平**衡，以便能获得高效的查找性能。**它可以在 O(logn) 时间内做查找，插入和删除等操作**。**红黑树是2-3树的一种等同**，但有些红黑树设定只能左边是红树，这种情况就是2-3树的一种等同了。

**对于AVL树来说，红黑树牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。**

由AVL演化出红黑树：**旋转操作+变色功能 两种行为效率**，==加入变色功能，减少旋转次数==

**单分支中不能出现两个连续节点都为红色；每个分支中到达根节点的黑色节点个数必须一致；**

==将插入和查询效率做了平衡，提高插入效率，损失查询效率==

==也会出现节点过深的问题==

#### HashMap节点数达到8，并且总体个数达到64时，会转换成红黑树，

#### jdk1.8以后的HashMap存储数据结构:链表长度超过8且数组长度大于64时,数据结构改为了红黑树 -> 涉及到查询效率，找HashMap的视频


HashMap的高效率

**HashMap是将key做hash算法，然后将hash值映射到内存地址，直接获取key所对应的数据**。

HashMap中数据存储的结构是数组+链表，**链表是为了解决hash碰撞问题**。

HashMap为什么快？主要是以下三点：


```
hash算法是高效的；
hash值到内存地址(数组索引)的算法是快速的；
根据内存地址(数组索引)可以直接获取对应的数据。
```

负载因子和阀值

负载因子又叫填充比，**是一个介于0和1之间的浮点数**，他决定了HashMap在扩容之前内部数组的填充度。**默认HashMap初始大小16，负载因子0.75**；

负载因子=元素个数/内部数组总数

在Jdk1.8以及以后的版本中,HashMap的底层数据结构由原来的数组+链表，调整为数组+链表/红黑树

首先明确链表的时间复杂度是O(n),红黑树时间复杂度是O(Logn)。**既然红黑树的复杂度优于链表，那么为为什么HashMap不直接使用红黑树代替链表呢？**

**树的节点占的空间是普通节点的两倍，在节点足够多的时候才会使用树形数据结构**，如果节点变少了还是会变回普通节点。总的来说就是节点太少的时候没必要转换、**不仅转换后的数据结构占空间而且转换也需要花费时间**。

**为了使hashCode分布良好,树形结构很少使用**。并且**在理想状态下受随机分布的hashCode影响**，链表中的节点遵循**泊松分布**，据统计**链表中的节点数是8的概率已经接近千分之一且此时链表的性能已经很差**。所以在这种比较罕见的和极端的情况下才会把链表转变为红黑树。

就是说大部分情况下HashMap还是使用链表，如果理想的均匀分布节点数不到8就已经自动扩容了。

#### B树 -》减少了IO次数(分支树大于2) -》当存储的数据量很大的时候会导致深度较大，增大查询时磁盘io次数，进而影响查询性能

#### B+Tree是在BTree的基础之上做的一种优化

1、**B+Tree每个节点可以包含更多的节点**，这个做的原因有两个，**第一个原因是为了降低树的高度，第二个原因是将数据范围变为多个区间，区间越多，数据检索越快**

2、**非叶子节点存储key，叶子节点存储key和数据**

3、**叶子节点两两指针相互连接（符合磁盘的预读特性），顺序查询性能更高**


==注意==：**在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点**，而且**所有叶子节点（即数据节点）之间是一种链式环结构**。因此可以对 B+Tree 进行两种查找运算：**一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。**

### B树、B+树支撑的数据量计算 -> 16 * 16 * 16 ,1600 * 1600 * 16

Mysql读数据需要磁盘预读，是page的整数倍，默认读取16K，也就是4 page; **一个磁盘块可以读取16K的数据**，**假设索引不占用空间，而每一条数据占用空间1Kb**，那么一个磁盘块最多只能读取16条数据；那么**三层B树可以读取的数据=16 * 16 * 16=4096条数据**

**非叶子节点存储了过多的data数据**

而Mysql中一般由几百万条数据；磁盘块大部分的空间用于存储data数据，这时候优化：磁盘块中不存储data数据，只在叶子节点存储数据；

**B+树在B树的基础上做了优化：非叶子节点不再存储data数据，只存储key和指针**

==非叶子节点 16Kb,而每一个key的空间为10b，那么一个非叶子节点的磁盘块可以存储 16*100=1600条数据；那么三层的B+树，1600 * 1600 * 16=40960000，可以支撑千万级的数据量==

#### B*树 -》在B+树的非叶子节点之间也建立了指针

### B+树 -》 InnoDB(数据和索引在一起，回表) + MYISAM(实际数据所在文件的地址；数据和索引不在一起，多了一次IO)

==注意==：1、InnoDB是通过**B+Tree结构对主键创建索引，然后叶子节点中存储记录**，**如果没有主键，那么会选择唯一键，如果没有唯一键，那么会生成一个6位的row_id来作为主键**;2、==如果创建索引的键是其他字段，那么在叶子节点中存储的是该记录的主键，然后再通过主键索引找到对应的记录,叫做回表==

存储引擎InnoDB: .idb  ==数据和索引在一个文件中； 叶子节点中存储的是一整行的数据==，是聚簇索引

MYISAM:  .MYD   .MYI  ==数据和索引分开存放的；叶子节点存放的是实际数据所在文件的地址，需要先从叶子节点中拿到地址，再到数据文件中根据地址读取数据==，是非聚簇索引；这样MyISAM多了一次IO，所以我们经常使用InnoDB

## ==Mysql的查询速率是很快的；那么我们使用Mysql慢的原因 -》IO、并发请求（并发请求多了，意味着有很多份缓存，内存不够，需要频繁替换内存，也就是吞吐量不够==）

## 索引优点 -> 大大减少了服务器需要扫描的数据量,帮助服务器避免排序和临时表,将随机io变成顺序io

## ==索引分类(5种)：主键索引、唯一索引、普通索引、全文索引、组合索引==

### 问题1：数据库会帮我们默认建索引吗？会

### **问题2：数据库会为哪些列建索引？ 特别注意：是唯一键（不是主键，主键也是唯一键）**

## ==面试技术名称（常问）- 回表、覆盖索引(组合索引)、最左匹配(组合索引)、索引下推(组合索引;根据name=?+age=?的数据从存储引擎中取出来)==

### 回表：Innodb的普通索引，存放主键id，需要根据主键id再到主键索引树中查找整行数据

我们可以给主键建立索引，也可以给普通列建立索引；**注意：普通索引的叶子节点中存放的是该列的主键，不是整行数据；**

==所以普通索引的过程是：1.先查找name的索引树(B+树)，找到主键id；2.再到主键id的索引树（B+树）中，找到整行数据，这个过程就是回表==

### 覆盖索引 -》 没有回表也就是覆盖索引-》应用在组合索引

覆盖索引的局限性还是很大的，但是在组合索引时使用还是比较多的，并且能用覆盖索引，尽量使用覆盖索引

### 最左匹配：--》存在于组合索引

#### 问题：现在有索引name+age,“ select * from emp where age=? ”这个sql如何优化** -》age+name

方案一：建立组合索引：age+name  -》 **更优：因为可以匹配查询条件：age,也可以匹配查询条件：age+name**

方案二：建立索引：age

方案三：sql查询条件更换位置  -》 不起作用

**注意：select * from emp where name=? and age=?不会有效果，因为mysql优化器会调整age和name的顺序**



#### 问题：下面三条sql语句，应该如何建索引？-> name+age , age（age占用空间更小）


```
select * from emp where name=? and age=?

select * from emp where age=?

select * from emp where name=?
```


**第一种：name+age , age (选这个)**

**因为age数据占用空间更小，IO查询次数较少，IO损耗更小**

第二种：age+name ,name 

第三种：age,name


### 索引下推 -》 谓词下推 -》 前提是组合索引

**谓词下推**：

select t1.name,t2.name from t1 join t2 on t1.id=t2.id

第一种方案：把t1/t2所有的列都加载的内存中，然后取name,id

**第二种方案：把t1.id/name, t2.id/name加载到内存中，这种就是谓词下推**

---

索引下推：select name,age from table where name=? and age=?

第一种方式：想将name=?的数据从存储引擎中取出来，在server这一层，再匹配age=？的数据

第二种方式：**根据name=?+age=?的数据从存储引擎中取出来**

索引条件 可以减少存储引擎查询基础表的次数，也可以减少server层从存储引擎接收数据的次数

==索引下推的前提是组合索引==

### **主键索引和唯一索引的区别 -》主键是否可以为空**

**一个区别：主键索引不能为空，唯一索引可以为空**

**空值的比较会慢一点，所以一般不建议为空**

**查询效率是一样的**

## 索引基本知识

### ==索引匹配方式-6种范围（一定记住） -》全值匹配、匹配最左前缀、匹配列前缀、匹配范围值、精确匹配某一列并范围匹配另外一列、只访问索引的查询(覆盖索引)==

全值匹配

匹配最左前缀

匹配列前缀

匹配范围值

精确匹配某一列并范围匹配另外一列

只访问索引的查询 -> 本质上就是覆盖索引

# ===========================

## 哈希索引（面试问的很少，掌握核心点就可以）

### ==精确匹配、memory、查询速度快、无法持久化、只包含哈希值和行指针，不存储字段值、哈希冲突、无法排序、范围查询、==

### 基于哈希表的实现，只能精确匹配，只有memory存储引擎显示支持哈希索引，查询速度很快 -》 缺点就是无法持久化，重启就没有了

基于哈希表的实现，只有**精确匹配**索引所有列的查询才有效

==在mysql中，只有memory的存储引擎显式支持哈希索引==

**哈希索引自身只需存储对应的hash值，所以索引的结构十分紧凑，这让哈希索引查找的速度非常快**

## 哈希索引的限制 

### 只包含哈希值和行指针，不存储字段值 -》 数据查找-行指针-行数据 -》内存中执行，速度快 -> 不是按索引值顺序排序的，所以无法进行排序 -》 只能精确匹配 -> 当出现哈希冲突时，存储引擎必须遍历链表中的所有行指针，逐行进行比较，直到找到所有符合条件的行 -》 哈希冲突时，维护代价高


1、**哈希索引只包含哈希值和行指针，而不存储字段值**，索引不能使用索引中的值来避免读取行

**数据查找：哈希值-》行指针-》行数据,因为在内存中执行，所以比较快**

2、哈希索引数据**并不是按照索引值顺序存储的，所以无法进行排序**

插入数据的顺序，跟存储顺序不一致，所以无法进行排序
    
3、哈希索引**不支持部分列匹配查**找，哈希索引是使用索引列的全部内容来计算哈希值

如果只支持部分列匹配的话，无法根据哈希值找到对应的数据

4、哈希索引支持等值比较查询，也**不支持任何范围查询**
    
5、访问哈希索引的数据非常快，除非有很多哈希冲突，**当出现哈希冲突的时候，存储引擎必须遍历链表中的所有行指针，逐行进行比较，直到找到所有符合条件的行**
    
    如何避免哈希冲突：编写优秀的哈希算法
    hashmap偷懒的方式：用数组长度取模--》这种方式禁用
    
    因为如果数据长度是16，那么只需要看低4位，那么可能出现低4位相同，高4位不相同，那么导致每次的值都会哈希冲突
    
    所以，在JDK的hashmap中有扰动函数,这样就可以高位参与运算，而不是低位参与运算
    
    如果哈希冲突严重的话，会导致链表无限长，那么查找时只能顺序按个查找，这样就变成了链表，而链表的时间复杂度比较低，所以尽量避免哈希冲突

6、**哈希冲突比较多的话，维护的代价也会很高**

## 哈希索引的应用：当存储索引需要占用很多空间的时候，使用哈希索引；缺点就是无法持久化，重启就没有了

## 案例 -》 存储大量的URL，根据URL进行查找 -》 B+树存储内容很大 -》 对url进行CRC32进行哈希(使用更小体积的索引) -》 数据不能频繁修改

当需要存储大量的URL，并且根据URL进行搜索查找，如果使用B+树，存储的内容就会很大

select id from url where url=""

也可以利用将url使用CRC32做哈希，可以使用以下查询方式：

select id fom url where url="" and url_crc=CRC32("")

此查询性能较高原因是使用体积很小的索引来完成查找

### CRC32：循环冗余校验算法 -》存储hbase的roukey时使用CRC32

CRC32：循环冗余校验算法   一种hash算法，大数据项目，存储hbase的roukey时使用CRC32

**将很长字符串通过CRC32得到指定长度的整数值，再根据整数值再进行哈希算法**

使用了较小的索引，B+树的深度就会变小，减少了IO次数，从而提供了性能

==哈希索引的应用：当存储索引需要占用很多空间的时候，使用哈希索引==

**哈希索引的缺点就是无法持久化，重启就没有了**

**有一个常量表有几百万行数据，并且很少修改，别的表又经常用到这个常量表，会将这个常量表使用memory存储引擎，使用hash索引；注意：数据不能频繁修改**

但是一般来说常量值不会太多，所以也不会用到哈希索引

## **面试题：如何避免哈希冲突问题？ -> 编写优秀的哈希算法**

## 组合索引-》包含多个列作为索引，需要注意的是正确的顺序依赖于该索引的查询

## 聚簇索引与非聚簇索引

### ==聚簇索引(数据和文件在一个文件中，使用覆盖索引、更新代价高、页分裂和页合并)==

### 聚簇索引-》 主键索引 -数据和文件放在一个文件中

#### 优点 -》数据访问更快，使用覆盖索引

1、可以把相关数据保存在一起

2、**数据访问更快，因为索引和数据保存在同一个树中**

3、**使用覆盖索引扫描的查询可以直接使用页节点中的主键值**


#### 缺点 -》 更新代价高，插入速度严重依赖插入顺序，插入新行或删除索引会引起页分裂

1、**聚簇数据最大限度地提高了IO密集型应用的性能**，**如果数据全部在内存，那么聚簇索引就没有什么优势**

2、**插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式**

3、**更新聚簇索引列的代价很高，因为会强制将每个被更新的行移动到新的位置**

4、==基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临页分裂的问题==

5、==聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候==

#### 怎么理解页分裂、页合并？ -》磁盘块是否满了 -》 页分裂、页合并 都会触发磁盘IO，索引的维护会更高，影响查询的执行效率

如果插入数据，维护索引时，对应磁盘块(数据页)的正好满了，要发生页分裂：原来的磁盘块扩展为两个磁盘块；原先磁盘块的数据**等分**为两份，上一半数据在第一个磁盘，后一半数据在第二个磁盘；这时候**两个磁盘块的空间没有充分利用，空间利用率不高，并且还会降低查询速度**

如果删除数据，维护相应的索引，如果两个磁盘块的数据总量不够一个磁盘块的容量，就会触发页合并：**两个数据页合并为一个数据页**

==页分裂、页合并 都会触发磁盘IO，索引的维护会更高，影响查询的执行效率==

类似大数据中的HBase的region分割

### 非聚簇索引 -》数据文件跟索引文件分开存放

## **问题：如果现在需要大量数据的Mysql迁移，应该怎么迁移？ 先将索引关闭，数据迁移后再将索引打开**

导数据之前，先将索引关闭；数据迁移以后再将索引打开

为什么？避免数据迁移过程中，一边导数据一边建索引，频繁的操作索引，导致迁移速度变慢


## ==覆盖索引 -》Innodb、MyISAM(主键索引可以，普通索引不行)支持覆盖索引；memory不支持 -》 减少数据访问量==

### 如果一个索引包含所有需要查询的字段的值，我们称之为覆盖索引

### 优势 -》 减少数据访问量 -》 IO密集型的范围查询会比随机从磁盘读取每一行数据的IO要少的多(索引是按照列值顺序存储的) -》 对INNODB表特别有用

1、索引条目通常远小于数据行大小，如果只需要读取索引，那么mysql就会极大的**减少数据访问量**

2、因为**索引是按照列值顺序存储的**，所以对于**IO密集型的范围查询会比随机从磁盘读取每一行数据的IO要少的多**

3、一些存储引擎如MYISAM在内存中只缓存索引，数据则依赖于操作系统来缓存，因此要访问数据需要一次系统调用，这可能会导致严重的性能问题

4、由于INNODB的聚簇索引，**覆盖索引对INNODB表特别有用**

### 案例 -》在explain的extra列可以看到using index的信息 -》 可以使用innodb的二级索引(也就是非聚簇索引)来覆盖查询

1.当发起一个被索引覆盖的查询时，在explain的**extra列可以看到using index的信息**，此时就使用了覆盖索引

2、在大多数存储引擎中，覆盖索引**只能覆盖那些只访问索引中部分列的查询**。不过，可以进一步的进行**优化，可以使用==innodb的二级索引【也就是非聚簇索引==来覆盖查询**。

# 索引优化小细节

## ==不要使用表达式、尽量使用主键、前缀索引(无法做orderby/groupby)、使用索引扫描来排序(需要满足索引的最左前缀)、推荐in、范围列可以用到索引(范围列后面的列无法用到索引)、不允许为空、尽量使用limit、单索引字段数不允许超过5个、单表索引建议控制在5个以内==

## 1.当使用索引列进行查询的时候尽量不要使用表达式，把计算放到业务层而不是数据库层

## 2.尽量使用主键查询，而不是其他索引，因此主键查询不会触发回表查询

## 3.使用前缀索引 -》 索引的选择性

### mysql无法使用前缀索引做order by 和 group by

### alter table xxx add key(city(7))

```
--查找最频繁出现的城市前缀，先从3个前缀字母开始，发现比原来出现的次数更多，可以分别截取多个字符查看城市出现的次数
select count(*) as cnt,left(city,3) as pref from citydemo group by pref order by cnt desc limit 10;
select count(*) as cnt,left(city,7) as pref from citydemo group by pref order by cnt desc limit 10;
--此时前缀的选择性接近于完整列的选择性

还可以通过另外一种方式来计算完整列的选择性，可以看到当前缀长度到达7之后，再增加前缀长度，选择性提升的幅度已经很小了
select count(distinct left(city,3))/count(*) as sel3,
count(distinct left(city,4))/count(*) as sel4,
count(distinct left(city,5))/count(*) as sel5,
count(distinct left(city,6))/count(*) as sel6,
count(distinct left(city,7))/count(*) as sel7,
count(distinct left(city,8))/count(*) as sel8 
from citydemo;

--计算完成之后可以创建前缀索引
alter table citydemo add key(city(7));
```

### 扩展：cardinality基数（在OLAP联机系统里面是必问的知识点）->hyperloglog算法

#### show index from citydemo; # 有属性cardinality

#### 某一列中去重的唯一值就是基数 -》 基数不需要精确，只需要能大概体现值的大小就可以

#### hyperloglog算法会用到基数、apache Kylin也会用到基数

## 4.使用索引扫描来排序 -》 需要满足索引的最左前缀的要求

### 如果explain出来的type列的值为index,则说明mysql使用了索引扫描来做排序

### 如果索引不能覆盖查询所需的全部列，那么就不得不每扫描一条索引记录就得回表查询一次对应的行，这基本都是随机IO，因此按索引顺序读取数据的速度通常要比顺序地全表扫描慢

### 总结

**总结：在使用排序的时候，如果where条件和order by中的一些列能够组成一个最左前缀匹配的话，它就会使用索引排序**

**第一种情况：如果where是范围的话，不能使用索引排序**

**第二种情况：如果order by中的顺序跟索引中排序不一样的话，也不能使用**

**组合索引，默认是升序排序；所以后面的排序必须是组合索引的排序是一模一样的；如果排序不一样，那么无法使用索引进行排序了**

**所以，在进行排序操作的时候，要注意一件事：如果排序列是索引的话，会使用索引排序；如果不是索引的话，会使用文件或临时表空间来进行排序的话，IO量是非常大的，性能是比较低的**

### order by需要全量加载数据，比较浪费内存；那么如何不浪费额外内存进行排序呢？ -》 使用索引扫描

### 索引本身就是有序的，所以利用索引进行排序，那么怎么排序呢？ -》 where条件和order by中的一些列组成一个最左前缀匹配 -》只有当索引的列顺序和order by子句的顺序完全一致，并且所有列的排序方式都一样时

## union all,in,or都能够使用索引，但是推荐使用in

union 和union all 推荐使用union all；因为union有distinct的操作，而去重是很麻烦的，浪费性能

通过执行计划看不出来，通过show profile可以看出实际执行时间的差距

## 补充exists:  

### **exists 必须是子查询**

### exists总结：外层循环控制内层循环，还有很有用处的，但是sql语句会比较复杂

### **exists 只要里面的子查询有结果，就相当于true，不需要关心结果是多少，那么外层的for循环就一定会执行**

### **外面的子查询，不能查询exists子查询中的字段**

```
select * from emp where deptno=20 or deptno = 30;
// 期望的结果

select * from emp where exists(select deptno from dept where deptno=20 or deptno=30)
// 结果是整张表
// 这个语句相当于两个for循环；
// 外层循环：select * from emp where
// 内层循环：select deptno from dept where deptno=20 or deptno=30
// exists 只要里面的子查询有结果，就相当于true，不需要关心结果是多少，那么外层的for循环就一定会执行，

// 那么应该如何修改？
// 加别名，不可行
select * from emp e where exists(select deptno from dept d where deptno=20 or deptno=30 and d.deptno=e.deptno)
// 执行结果还是整张表
// 原因：因为and 的优先级 大于or的优先级； d.deptno=e.deptno会先执行，or deptno=30后执行
// 不是很理解？？


// exsits 正确结果
select * from emp e where exists(select deptno from dept d where (deptno=20 or deptno=30) and d.deptno=e.deptno)
// 期望结果

exists总结：外层循环控制内层循环，还有很有用处的，但是sql语句会比较复杂

2.外面的子查询，不能查询exists子查询中的字段????
select *,d.deptno from emp e where exists(select deptno from dept d where (deptno=20 or deptno=30) and d.deptno=e.deptno)  ??能执行成功吗

```

## 范围列可以用到索引，但是范围列后面的列无法用到索引，索引最多用于一个范围列

## 强制类型转换会全表扫描 -》 字符串转int

## 更新十分频繁，数据区分度不高的字段上不宜建立索引

### 一般区分度在80%以上的时候就可以建立索引，区分度可以使用 count(distinct(列名))/count(*) 来计算

## 创建索引的列，不允许为null，可能会得到不符合预期的结果

## 当需要进行表连接的时候，最好不要超过三张表，因为需要join的字段，数据类型必须一致

### ==补充join的多种方式原理==

#### Nested-Loop algorithms 嵌套循环算法

#### **Simple Nested-Loop Join** ：驱动表r 取每一条记录 去匹配s(匹配表)的列
![404](61522FEF681F4CD4B275455E7E9A788B)

#### **Index Nested-Loop Join -> 要求匹配表s中有索引，根据关联的字段的索引进行查找，当在索引上找到符合的值，再回表进行查询** 

要求匹配表s中有索引，根据关联的字段的索引进行查找，当在索引上找到符合的值，再回表进行查询

如果非驱动表s的关联键是主键的话，性能会非常高

如果不是主键，要进行多次回表查询，先关联索引，然后根据二级索引的主键id进行回表操作

![405](6D22A02534904A9983C2E3B8E1922A26)

#### **Blocked Nested-Loop Join -》 匹配表没有索引、join buffer缓冲区(256)、N-1个join buffer**
![406](BC14A99895364C4FA70D56E817D9D635)

如果匹配表没有索引，会采用Block Nested-loop Join，中间有个join buffer缓冲区，将驱动表的所有join相关的列都缓存到join buffer中，然后批量与匹配表进行匹配，将第一种多次比较合并为一次，降低非驱动表的访问频率。

默认情况下join_buffer_size=256K

在查找的时候mysql会将所有的需要的列缓存到join buffer中，包括select列，而不是仅仅只缓存关联列。

在一个有N个join关联的SQL中会在执行时候分配N-1个join buffer

#### show variables like '%join_buffer%'

join buffer默认为256K；如果数据过大，buffer放不下，那么无法采用Block Nested-loop join,所以可以调大 (join_buffer_size=262144), 调整的大小要考虑内存的大小

show variables like '%join_buffer%'

### **问题：table A join table B ，一定是A表joinB表吗？不一定；也有可能是B join A；优化器优化时决定**

可以强制指定 A join B：A constact(???) join B

### **所以一般为：A.外建 join B.主键**

### **最好是：小表 join 大表 ，主要是执行次数的数量**；

小表放内存，大表放磁盘，这样可以是小表快速加载； 小表 join 大表 类似大数据中的 mapjoin (Hive)


### 问题：为什么要引入 join-on的形式？-》 join指定的连接条件， on指定了筛选条件

### 扩展：大表 join 大表 -》唯一的方式：采用分区运算，也（就是分区表），手动限定范围 或者 把语句拆分为N条结果来执行

大表 join 大表，**本质上没有太好的匹配方式**，**唯一的方式：采用分区运算，也（就是分区表）**，**手动限定范围 或者 把语句拆分为N条结果来执行**，分而治之的思想，类似hive

#### **大表 join 大表，还要排序**；排序是order by; **hive中有sort by、distbut by（？？？）、classer by,这些方式mysql不一定支持**；但是可以采用n个小表 join，然后排序；然后再合并到一起，**这样的操作复杂度比较高，需要很多临时表，IO量会增加**

### 问题：MYSQL 中 LEFT JOIN ON 后的AND(在临时表生成的过程时，ON中的条件不管是否为真，都将返回左表) 和WHERE(在临时表生成后，再对临时表的数据进行过滤)

LEFT JOIN ON WHERE：在临时表生成后，再对临时表的数据进行过滤，再返回左表。

LEFT JOIN ON AND：在临时表生成的过程时，ON中的条件不管是否为真，都将返回左表。

**用and这种情况也比较多，比方说就是想统计满足条件的左边表的记录，就算为空，也要列出来，那这种方法就很好使用，否则还要在连接一次用户表。**

对于inner join,on and和on where结果一致
在使用inner join时，不管是对左表还是右表进行筛选，on and和on where都会对生成的临时表进行过滤

## 能使用limit的时候尽量使用limit -> ==limit的作用：是限制输出，不是分页==；



limit到限制的数量后，不会再往下进行搜索


### 单表索引建议控制在5个以内

#### 表中列为varchar类型，长度为10个字节，如果列值为空字符串，会不会占用空间？会

#### 如果值为1个字节，那么存储空间是几？ 10个字节

## 单索引字段数不允许超过5个（组合索引）

字段过多浪费存储空间

## 创建索引的时候应该避免以下错误概念->索引越多越好 ->过早优化，在不了解系统的情况下进行优化

# ==面试MySql调优应该怎么说？-> 查询慢，执行计划，具体的调整说一下==

不要上来就把思维导图中的内容说一遍，应该是：在公司的时候，查询比较慢，通过执行计划查询发现type是all 、index或range，我调整以后type变成const，怎么调的具体再说一下


思维导图中的内容是在写sql时要注意的地方，只有出问题的时候，才会做实质性的优化

# ==索引监控（不是很重要的点）->show status like 'Handler_read%'; -> 重点关注：Handler_read_key、Handler_read_rnd_next，如果这两个值比较大，说明索引生效了-》注意：这是全部的索引信息，不是单个的索引==

    show status like 'Handler_read%';
    
    Handler_read_first：读取索引第一个条目的次数
        // 访问根节点的次数
    
    Handler_read_key：通过index获取数据的次数
    Handler_read_last：读取索引最后一个条目的次数
    Handler_read_next：通过索引读取下一条数据的次数
    Handler_read_prev：通过索引读取上一条数据的次数
    Handler_read_rnd：从固定位置读取数据的次数
    Handler_read_rnd_next：从数据节点读取下一条数据的次数

**这些值在索引优化中非常有用：知道索引的有没有作用、效率**

==重点关注：Handler_read_key、Handler_read_rnd_next，如果这两个值比较大，说明索引生效了；如果值很小，说明没有用到索引，或索引建的有问题==

**注意：这是全部的索引信息，不是单个的索引**


## ==索引整理的时候会将现有的数据锁住，所以不建议这样的操作；新迁移的数据可以做索引整理==

# ====================================

# 查询优化

在编写快速的查询之前，需要清楚一点，**真正重要的是响应时间**，而且要知道在整个SQL语句的执行过程中**每个步骤都花费了多长时间，要知道哪些步骤是拖垮执行效率的关键步骤**，想要做到这点，**必须要知道查询的生命周期，然后进行优化**，不同的应用场景有不同的优化方式，不要一概而论，具体情况具体分析

## 查询慢的原因

网络、CPU、IO、上下文切换、系统调用、生成统计信息(profiles/schema)、锁等待时间

### 面试中问到Mysql中的锁，应该如何回答？ -》 存储引擎相关，InnoDB(共享锁、排它锁；行锁、表锁)、MYISAM(共享读锁、独占写锁；表锁)、自增锁、间隙锁

    Mysql中的锁跟存储引擎相关，
    
    InnoDB：共享锁、排它锁；可以锁表，也可以锁行；锁的对象：索引【锁的列是索引列的话，是行锁；如果不是索引会从行锁退化为表锁】
    
    MyISAM：共享读锁、独占写锁；只能锁表；

    自增锁：
    
    间隙锁：

## 优化数据访问

### 1.查询性能低下的主要原因是访问的数据太多，我们可以通过**减少访问数据量的方式进行优化**

#### **确认应用程序是否在检索大量超过需要的数据** -》 查看执行计划-rows

#### 数据量大到什么程序不会索引呢？《高效能Mysql》说阈值是30%

# 面试的时候如何说分区，建议带上应用场景：哪个业务有哪张表数据量比较大或查询比较慢，因此做了分区，把热数据和历史数据做了区分

# 面试聊业务时，别慌，你是最熟悉业务的，除非有特别大的漏洞；如果被指出bug，就说我回去跟我的leader说一下