[TOC]

# 2019.12.17的公开课：面试表达

# 滴滴面试

![701](C81C85FD73524490B7697BD96C9409E8)
![702](036AB1FA5EA2456EB12DAF9FFC133E7A)

面试问的比较深

三面挂了，原因是什么呢？表达技巧、自我介绍(照稿念不好)、聊项目（不太会，不太精通的地方，直接告诉就行；不要不懂装懂）

金融工作，需要金融知识

面试过程中要表明自己的态度

# 分区表

## 如何使用分区表

问题：如果需要从非常大的表中查询出某一段时间的记录，而这张表中包含很多年的历史数据，数据是按照时间排序的，此时应该如何查询数据呢？

因为数据量巨大，**肯定不能在每次查询的时候都扫描全表**。**考虑到索引在空间和维护上的消耗，也不希望使用索引**，**即使使用索引，会发现会产生大量的碎片，还会产生大量的随机IO**，但是当数据量超大的时候，索引也就无法起作用了，此时可以考虑使用分区来进行解决

查询的数据是某一个批次的数据、或某个类型的数据

### 全量扫描数据，不要任何索引

**使用简单的分区方式存放表，不要任何索引，根据分区规则大致定位需要的数据为止**，==通过使用where条件将需要的数据限制在少数分区中，这种策略适用于以正常的方式访问大量数据==

### 索引数据，并分离热点

**大公司中，热数据放在HDFS中，历史数据放在磁盘中，并且不挂载到HDFS集群中**

AWS中，热数据放在S3中【S3收费很昂贵】；冷数据放在冰山【冰山会对数据进行压缩，减少存储空间，并且也比较便宜】

如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以**将这部分热点数据单独放在一个分区中，让这个分区的数据能够有机会都缓存在内存中**，这样查询就可以只访问一个很小的分区表，能够使用索引，也能够有效的使用缓存

**这个方案适用大数据量；10G以下的数据量不建议使用这个方案**

冷数据查询时间比较长，类似移动的通话记录，近几个月可以在app查询，再久的数据需要去营业厅拿身份证进行查询【需要身份验证、一些权限】


## 在使用分区表的时候需要注意的问题

1.**null值会使分区过滤无效**

==2.分区列和索引列不匹配，会导致查询无法进行分区过滤==

3.选择分区的成本可能很高【插入、维护、查询、成本的成本；分区：先按年，再按天】

**问题：原先公司的数据量有多少？几百万条，超过几亿条一般说数据大小，也就是几个G**

4.**打开并锁住所有底层表的成本可能很高**

5.**维护分区的成本可能很高**

==结论：在使用分区列的时候，最好使用易区分、有特征的的：时间【年龄】、日期、类别；不建议用id进行分区==


# 服务器参数设置

**如何修改mysql的配置？ vi /etc/my.cnf**
    
**[mysqld] 服务器方面的**

官网 查看配置参数  -》     
    

## general【不需要优化】

skip-grant-tables 很重要

datadir=/var/lib/mysql：数据文件存放的目录

socket=/var/lib/mysql/mysql.sock：**mysql.socket表示server和client在同一台服务器，并且使用localhost进行连接，就会使用socket进行连接**
	
	service mysqld stop
    mysql -uroot -p 连接时报错，提示：can't connect to local Mysql Server through socket ''
    一般也很少通过localhost连接mysql数据库
	

pid_file=/var/lib/mysql/mysql.pid：存储mysql的pid

port=3306：mysql服务的端口号

default_storage_engine=InnoDB：mysql存储引擎

skip-grant-tables：**当忘记mysql的用户名密码的时候，可以在mysql配置文件中配置该参数，跳过权限表验证，不需要密码即可登录mysql**


## character

utf8mb4

character_set_client**客户端数据的字符集**

character_set_connection：mysql处理客户端发来的信息时，会把这些数据转换成连接的字符集格式

character_set_resultsmysql发送给客户端的结果集所用的字符集

character_set_database**数据库默认的字符集**

character_set_servermysql server的默认字符集

## connection

### ==连接池如果不熟悉，到基础班看一下==

**max_connections**：mysql的最大连接数，如果数据库的并发连接请求比较大，应该调高该值
    
    show variables like '%max_connection%'  //每台电脑不相同
    set global max_connnections=1024
    
    show processlist; //查看已有连接

**max_user_connections**：限制每个用户的连接个数**；0意味着不限制**

**back_log**：mysql能够暂存的连接数量

当mysql的线程在一个很短时间内得到非常多的连接请求时，就会起作用，如果mysql的连接数量达到max_connections时，新的请求会被存储在堆栈中，以等待某一个连接释放资源，如果等待连接的数量超过back_log,则不再接受连接资源
	
	注意：值越大，等待的请求越多，客户端等待时间越长；所以不建议过大
	
	原理跟线程池一样
	blockqueue阻塞队列；
	拒绝策略有4种
	

**wait_timeout**: mysql在关闭一个**非交互的连接**之前需要等待的时长

**问题：什么是交互连接、非交互连接？** -》 交互连接(短连接)、非交互连接(长连接)

    mysql、JDBC、navicat、sqlyong 
    
    关键在于保持的连接是长连接还是短连接
    长连接：wait_timeout
    短连接：interactive_timeout
    
    **能用长连接就用长连接**
    **连接池就属于是长连接**
    
    长连接也有问题：长时间没有连接进入，需要关闭；有请求进入再打开
    
    **JDBC不能设置长短连接，JDBC是交互连接**

**interactive_timeout**: 关闭一个交互连接之前需要等待的秒数

## 补redo/undo/binlog

### 问题：了解mysql的日志吗？redo /undo /binlog

    提到mysql的日志有三种日志文件：redo log 、undo log 、binlog 
    需要注意：redo 、undo都归属于InnoDB存储引擎
    binlog归属于Mysql server这个层面的
    
### 问题：那么redo /undo /binlog各自都有什么作用？

    一个事务中包含n多个sql操作，要么全部成功，要么全部失败；包含4中特性：ACID
    四个特性中，哪个最重要？C一致性最重要，是根本追求
    
    ACID分别是通过什么机制实现的呢？
    A（Actomicity）原子性 -》通过 undo log实现
    C（Consistent）一致性 -》通过 原子性、隔离性、持久性 实现的
    I（Isolation）隔离性 -> 通过 锁 实现
    D（Durable）持久性 -》 通过 redo log 实现
    
### 概述：LogBuffer -OS Buffer - redo log file

**当发生数据修改的时候，innodb引擎会先将记录写到redo log中，并更新内存**，此时更新就算是完成了，同时**innodb引擎会在合适的时机将记录操作到磁盘中**

==Redolog是固定大小的，是循环写的过程==

有了redolog之后，innodb就可以保证及时数据库发生异常重启，之前的记录也不会丢失，叫做**crash-safe**
    
也就是：**用户submit一个操作**， 会将**记录保存到redo log中**：具体过程是**redo log会先保存到log buffer的内存空间**中，**log buffer再将操作写到 OS buffer**，**OS buffer通过系统调用fsync()将数据写到磁盘的redolog文件中**
    
![703](BFEFA6705C89474DB7F6046908D5A217)
    
### 问题：redolog 如何保证持久性？【redolog 前滚日志】

    log buffer提供了三种方式
    哪种方式最安全？1号方式最安全
    数据安全 + 性能，建议使用2号方式【少了一次log buffer到OS buffer的拷贝过程】
    
![704](631A77A9C403499F8521A674006AED79)

### 问题：undolog如何保证原子性 【undolog 回滚日志】

undo log是**为了实现事务的原子性**，在mysql数据库InnoDB存储引擎中，还**用undo log来实现多版本并发控制（简称MVCC）**
    
**在操作任何数据之前**，**首先将数据备份到一个地方**（这个存储数据局备份的地方称为undo log）。然后**进行数据的修**改。==如果出现了错误或用户执行了ROLLBACK语句，系统可以利用undo log中的备份将数据恢复到事务开始之前的状态==
    
注意：**undo log是逻辑日志**，可以理解为：

    当delete一条记录时，undo log中会记录一条对应的insert记录
    当insert一条记录时，undo log中会记录一条对应的delete记录
    当update一条记录时，它记录一条对应相反的update记录

### Binlog

**binlog中会记录所有的逻辑，并且采用追加写的方式**

一般在企业中数据库会有**备份系统，可以定期执行备份**，备份的周期可以自己设置

**恢复数据的过程**：1.找到**最近一次的全量备份数据**；2.**从备份的时间点开始，将备份的binlog取出来，重放到要恢复的那个时刻**

### 数据更新的流程-redolog的两阶段提交【面试会被问到】-》 prepare阶段+commit状态

![705](F589E6BABB144ED0BBC2FDB8255EDF03)
![706](D57DE6A587C349FB982E8211FCF71427)

#### 问题：为什么有prepare阶段(redo log)  和  commit状态(binlog) -》保证数据的最终一致性
    
redo log的两阶段提交，保证数据的最终一致性

因为会有数据安全问题

![707](60172392C7174747A3566DEA9EE973BD)

### 问题：binlog与redo log的区别？

**Binlog是server层的日志**，主要做mysql功能层面的事情
    
> 与redo日志的区别：
> 
> 1.==redo是innodb独有的，binlog是所有引擎都可以使用的==
> 
> 2.==redo是物理日志，记录的是在某个数据也上做了什么修改==，**binlog是逻辑日志，记录的是这个语句的原始逻辑**【原始逻辑：之前做什么操作，现在还做什么操作】
> 
> 3.**redo是循环写的，空间会用完**;**binlog是可以追加的**，不会覆盖之前的日志信息【追加写：顺序读写，效率高（比随机读写的效率高）】
    
所以，能顺序写，尽量顺序写
    
**提到循环写和追加写，联想到MQ的数据是放在内存中**
    
==而Kafka的数据在磁盘，既然数据在磁盘，为什么还那么快呢？
        因为1.顺序读写的过程；2.零拷贝，缺少了两次用户态和内核态的切换（也就是数据不需要在用户态内核态进行拷贝；应用程序和网卡都可以读到缓冲区的数据），增加了读取的效率==

### 面试：什么是零拷贝【会问到哦】

用户态内核态不需要拷贝数据 -》 kafka（sendfile+mmap）

用户态通过系统调用read，将FD写入用户空间；再通过系统调用write将fd写到网卡；这个过程涉及到数据在用户态和内核态的拷贝

有了Sendfile(),是用户调用系统调用sendfile，内核将内容读到缓存区，由缓存区直接写到网卡，没有数据在用户态和内核态之间拷贝了

sendfile 加上 mmap可以组成kafka（是基于JVM的一个用户空间进程），可以通过mmap挂载到文件files；

消费者通过偏移量来读数据，走sendfile零拷贝

kafka通过mmap看到的内存空间，内核也能看到，这样就减少了系统调用，减少数据拷贝,这样就能实现网卡写入文件时很快

![103](7189C6697EDC4D24BDD04EFDC446548E)
    

## log

log_error：**指定错误日志文件名称**，用于记录当mysqld启动和停止时，以及服务器在运行中发生任何严重错误时的相关信息

log_bin：**指定二进制日志文件名称**，用于记录对数据造成更改的所有查询语句【**在做主从复制时很重要，默认不开启，需要手动开启;并且强烈建议开启**；==开启会影响性能，但是保证数据的安全性==】

    bin_log的等级=row  
    log-bin=master-bin
    biglog-format=ROW

**binlog_do_db** ：指定将更新记录到二进制日志的数据库，**其他所有没有显式指定的数据库更新将忽略，不记录在日志中**

问题：binlog-do-db指定的数据库越多越好吗？

> 不是，binlog-do-db指定的数据库越多，说明要生成的binlog日志文件越大，恢复越麻烦；虽然设置上是好的，但是会增加吞吐量；所以要做合理选择：哪些数据库的数据重要就存biglog，如果不重要、或能及时恢复，就没必要做biglog日志了
    

**binlog_ignore_db** ： 指定不将更新记录到二进制日志的数据库

==**注意：新项目上线，会设置binlog-do-db或binlog-ignore-db，并且这个设置很重要；一般有经验的DBA或运维会做这件事**==


**sync_binlog** ：指定多少次写日志后同步磁盘

general_log ：是否开启查询日志记录

    默认是关闭；如果业务比较复杂，并且注重mysql性能的话，建议打开
    虽然打开会消耗服务器性能

**general_log_file** ：指定查询日志文件名，用于记录所有的查询语句

==slow_query_log== : 是否开启慢查询日志记录

    一般会开启

**slow_query_log_file**: 指定慢查询日志文件名称，用于记录耗时比较长的查询语句

**long_query_time** : 设置慢查询的时间，超过这个时间的查询语句才会记录日志

**log_slow_admin_statements** : 是否将管理语句写入慢查询日志

    建议开启；服务器监控，日志监控

### 问题：binlog-do-db指定的数据库越多越好吗？

不是，binlog-do-db指定的数据库越多，说明要生成的binlog日志文件越大，恢复越麻烦；虽然设置上是好的，但是会增加吞吐量；所以要做合理选择：哪些数据库的数据重要就存biglog，如果不重要、或能及时恢复，就没必要做biglog日志了

### 问题：什么是慢查询，什么是快查询？-》long_query_time默认设置为10s，超过这个设置的查询都算慢查询

long_query_time默认配置的是10s，超过10s的都算慢查询

1.即席查询 ad_hoc ：在尽可能快的时间内把结果查询出来
即席查询在数据仓库、OLAP中使用比较多

2.定时查询  执行批量任务
    
### 问题：什么是全栈工程师？

最开始的含义：前端的四个技术都会，后来演化为：全都会
    